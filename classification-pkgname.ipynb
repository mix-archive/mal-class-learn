{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pkg_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QQ空间</td>\n",
       "      <td>com.qzone</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/995...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>搜狗输入法</td>\n",
       "      <td>com.sohu.inputmethod.sogou</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/686...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC浏览器</td>\n",
       "      <td>com.UCMobile</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QQ同步助手</td>\n",
       "      <td>com.tencent.qqpim</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>京东</td>\n",
       "      <td>com.jingdong.app.mall</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/719...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>极速数据恢复</td>\n",
       "      <td>com.ansxtech.wx</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/540...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>中国好故事</td>\n",
       "      <td>com.chinaso.stories</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>蜂鸟部落</td>\n",
       "      <td>com.fengniaobuluocps</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>云智充</td>\n",
       "      <td>com.dream.zncd.intelligentcharge</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>天天在线</td>\n",
       "      <td>com.ttzx.app</td>\n",
       "      <td>/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/526...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2231 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                          pkg_name  \\\n",
       "0       QQ空间                         com.qzone   \n",
       "1      搜狗输入法        com.sohu.inputmethod.sogou   \n",
       "2      UC浏览器                      com.UCMobile   \n",
       "3     QQ同步助手                 com.tencent.qqpim   \n",
       "4         京东             com.jingdong.app.mall   \n",
       "...      ...                               ...   \n",
       "2226  极速数据恢复                   com.ansxtech.wx   \n",
       "2227   中国好故事               com.chinaso.stories   \n",
       "2228    蜂鸟部落              com.fengniaobuluocps   \n",
       "2229     云智充  com.dream.zncd.intelligentcharge   \n",
       "2230    天天在线                      com.ttzx.app   \n",
       "\n",
       "                                                   path  \n",
       "0     /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/995...  \n",
       "1     /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/686...  \n",
       "2     /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/109...  \n",
       "3     /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/846...  \n",
       "4     /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/719...  \n",
       "...                                                 ...  \n",
       "2226  /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/540...  \n",
       "2227  /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/539...  \n",
       "2228  /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/539...  \n",
       "2229  /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/423...  \n",
       "2230  /run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apks/526...  \n",
       "\n",
       "[2231 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "normal_apps_path = Path(\"/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apps.csv\")\n",
    "normal_apps = pd.read_csv(normal_apps_path)\n",
    "\n",
    "normal_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>诈骗类型</th>\n",
       "      <th>APP名称</th>\n",
       "      <th>APP包名</th>\n",
       "      <th>apk文件名</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.tlfy</td>\n",
       "      <td>1719354472896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>慈联</td>\n",
       "      <td>com.zjasmdxa.fiyyrs</td>\n",
       "      <td>1719372932233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>国能APP</td>\n",
       "      <td>com.ekatyhlo.mirpwb</td>\n",
       "      <td>1719402160462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.xqrh</td>\n",
       "      <td>1719347300879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>贷款诈骗</td>\n",
       "      <td>还呗</td>\n",
       "      <td>com.example.byaf.byaf</td>\n",
       "      <td>1719398212372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.khwm</td>\n",
       "      <td>1719713801202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>慈联</td>\n",
       "      <td>com.dwrcsaht.hzcelz</td>\n",
       "      <td>1719701530760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.xhno</td>\n",
       "      <td>1719698243724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>投资理财</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.bckx</td>\n",
       "      <td>1719699541723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>贷款诈骗</td>\n",
       "      <td>微粒分期</td>\n",
       "      <td>chdhcdbc.ecdddgad.bbegehce</td>\n",
       "      <td>1719723296650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     诈骗类型  APP名称                       APP包名         apk文件名\n",
       "0    投资理财   共富工程                    uni.tlfy  1719354472896\n",
       "1    投资理财     慈联         com.zjasmdxa.fiyyrs  1719372932233\n",
       "2    投资理财  国能APP         com.ekatyhlo.mirpwb  1719402160462\n",
       "3    投资理财   共富工程                    uni.xqrh  1719347300879\n",
       "4    贷款诈骗     还呗       com.example.byaf.byaf  1719398212372\n",
       "..    ...    ...                         ...            ...\n",
       "193  投资理财   强国复兴                    uni.khwm  1719713801202\n",
       "194  投资理财     慈联         com.dwrcsaht.hzcelz  1719701530760\n",
       "195  投资理财   强国复兴                    uni.xhno  1719698243724\n",
       "196  投资理财   共富工程                    uni.bckx  1719699541723\n",
       "197  贷款诈骗   微粒分期  chdhcdbc.ecdddgad.bbegehce  1719723296650\n",
       "\n",
       "[783 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malware_paths = [*Path(\"/run/media/mix/64B2AAFCB2AAD1BA/APP/\").glob(\"**/*.xlsx\")]\n",
    "malware_apps = pd.concat(pd.read_excel(file) for file in malware_paths)\n",
    "\n",
    "malware_apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>pkg_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ空间</td>\n",
       "      <td>com.qzone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>搜狗输入法</td>\n",
       "      <td>com.sohu.inputmethod.sogou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>UC浏览器</td>\n",
       "      <td>com.UCMobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ同步助手</td>\n",
       "      <td>com.tencent.qqpim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>京东</td>\n",
       "      <td>com.jingdong.app.mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.khwm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>慈联</td>\n",
       "      <td>com.dwrcsaht.hzcelz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.xhno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.bckx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>fraud_loan</td>\n",
       "      <td>微粒分期</td>\n",
       "      <td>chdhcdbc.ecdddgad.bbegehce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type    name                    pkg_name\n",
       "0               normal    QQ空间                   com.qzone\n",
       "1               normal   搜狗输入法  com.sohu.inputmethod.sogou\n",
       "2               normal   UC浏览器                com.UCMobile\n",
       "3               normal  QQ同步助手           com.tencent.qqpim\n",
       "4               normal      京东       com.jingdong.app.mall\n",
       "...                ...     ...                         ...\n",
       "3009  fraud_investment    强国复兴                    uni.khwm\n",
       "3010  fraud_investment      慈联         com.dwrcsaht.hzcelz\n",
       "3011  fraud_investment    强国复兴                    uni.xhno\n",
       "3012  fraud_investment    共富工程                    uni.bckx\n",
       "3013        fraud_loan    微粒分期  chdhcdbc.ecdddgad.bbegehce\n",
       "\n",
       "[3014 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.DataFrame(columns=[\"type\", \"name\", \"pkg_name\"])\n",
    "\n",
    "for name, pkg_name, *_ in normal_apps.values:\n",
    "    merged.loc[len(merged)] = [\"normal\", name, pkg_name]\n",
    "\n",
    "for type, name, pkg_name, *_ in malware_apps.values:\n",
    "    merged.loc[len(merged)] = [\n",
    "        {\"投资理财\": \"fraud_investment\", \"贷款诈骗\": \"fraud_loan\"}[type],\n",
    "        name,\n",
    "        pkg_name,\n",
    "    ]\n",
    "\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(114514)\n",
    "\n",
    "unique_types = merged[\"type\"].unique()\n",
    "num_labels = len(unique_types)\n",
    "\n",
    "# Create a label mapping\n",
    "label_dict = {label: i for i, label in enumerate(unique_types)}\n",
    "id2label = {i: label for label, i in label_dict.items()}\n",
    "\n",
    "# Prepare the features (name:pkg_name) and labels\n",
    "merged[\"text\"] = merged[\"name\"] + \":\" + merged[\"pkg_name\"]\n",
    "merged[\"label\"] = merged[\"type\"].map(label_dict)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    merged[\"text\"].values,\n",
    "    merged[\"label\"].values,\n",
    "    test_size=0.1,\n",
    "    random_state=114514,\n",
    "    stratify=merged[\"label\"].values,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "# Create a custom dataset\n",
    "class AppDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# First, we need to convert text to features for SMOTE\n",
    "# SMOTE can't work directly on text, so we'll use TF-IDF to vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=114514)\n",
    "X_train_resampled, y_train_resampled, *_ = smote.fit_resample(X_train_vec, train_labels)\n",
    "\n",
    "# Convert resampled indices back to text\n",
    "# We need to handle the synthetic samples\n",
    "train_texts_resampled = []\n",
    "for i, x_vec in enumerate(X_train_resampled):\n",
    "    if i < len(train_texts):  # Original sample\n",
    "        train_texts_resampled.append(train_texts[i])\n",
    "    else:  # Synthetic sample\n",
    "        # Find nearest neighbors to create a realistic text representation\n",
    "        # Here we use the original text of the same class\n",
    "        same_class_indices = [\n",
    "            j for j, y in enumerate(train_labels) if y == y_train_resampled[i]\n",
    "        ]\n",
    "        if same_class_indices:\n",
    "            # Choose a random original text from the same class\n",
    "            idx = same_class_indices[\n",
    "                torch.randint(0, len(same_class_indices), (1,)).item()\n",
    "            ]\n",
    "            train_texts_resampled.append(train_texts[idx])\n",
    "\n",
    "# Create datasets with resampled data\n",
    "train_dataset: AppDataset = AppDataset(\n",
    "    train_texts_resampled, y_train_resampled, tokenizer\n",
    ")\n",
    "val_dataset: AppDataset = AppDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Create DataLoaders (unchanged)\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=num_labels, id2label=id2label, label2id=label_dict\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a98980969da4dc183d73db01e1529cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6170d5a92819438bb83bca0e1886b3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1326\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       0.99      1.00      0.99       224\n",
      "fraud_investment       0.98      0.91      0.95        67\n",
      "      fraud_loan       0.67      0.91      0.77        11\n",
      "\n",
      "        accuracy                           0.97       302\n",
      "       macro avg       0.88      0.94      0.90       302\n",
      "    weighted avg       0.98      0.97      0.97       302\n",
      "\n",
      "Saved best model!\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a30f2478e8544ecba4b9675f5f3ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3930bd83524b4680aff115aa12dbcc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1417\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       0.99      1.00      0.99       224\n",
      "fraud_investment       0.95      0.94      0.95        67\n",
      "      fraud_loan       0.80      0.73      0.76        11\n",
      "\n",
      "        accuracy                           0.97       302\n",
      "       macro avg       0.91      0.89      0.90       302\n",
      "    weighted avg       0.97      0.97      0.97       302\n",
      "\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2934075ddf7f42d082adaca0ca56c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e6c888ddcf40bb9c1c2cc0bfb022e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1762\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       0.98      1.00      0.99       224\n",
      "fraud_investment       0.95      0.94      0.95        67\n",
      "      fraud_loan       0.78      0.64      0.70        11\n",
      "\n",
      "        accuracy                           0.97       302\n",
      "       macro avg       0.90      0.86      0.88       302\n",
      "    weighted avg       0.97      0.97      0.97       302\n",
      "\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba22a690769f4cc6998099bf939c7e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c101c1a6984342b09ab8f0ab9eb0b6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1762\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       0.98      1.00      0.99       224\n",
      "fraud_investment       0.95      0.94      0.95        67\n",
      "      fraud_loan       0.78      0.64      0.70        11\n",
      "\n",
      "        accuracy                           0.97       302\n",
      "       macro avg       0.90      0.86      0.88       302\n",
      "    weighted avg       0.97      0.97      0.97       302\n",
      "\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a942ed3a24994cd280cdbbe3580f154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/377 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40691d68120141f08cedc5e2722b6a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.1762\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       0.98      1.00      0.99       224\n",
      "fraud_investment       0.95      0.94      0.95        67\n",
      "      fraud_loan       0.78      0.64      0.70        11\n",
      "\n",
      "        accuracy                           0.97       302\n",
      "       macro avg       0.90      0.86      0.88       302\n",
      "    weighted avg       0.97      0.97      0.97       302\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    val_loss, val_preds, val_labels = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(val_labels, val_preds, target_names=unique_types))\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_roberta_model.pt\")\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_roberta_model.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
