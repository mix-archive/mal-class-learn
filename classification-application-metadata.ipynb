{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/openpyxl/styles/stylesheet.py:237: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>pkg_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ空间</td>\n",
       "      <td>com.qzone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>搜狗输入法</td>\n",
       "      <td>com.sohu.inputmethod.sogou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>UC浏览器</td>\n",
       "      <td>com.UCMobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ同步助手</td>\n",
       "      <td>com.tencent.qqpim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>京东</td>\n",
       "      <td>com.jingdong.app.mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.khwm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>慈联</td>\n",
       "      <td>com.dwrcsaht.hzcelz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3011</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.xhno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.bckx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>fraud_loan</td>\n",
       "      <td>微粒分期</td>\n",
       "      <td>chdhcdbc.ecdddgad.bbegehce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type    name                    pkg_name\n",
       "0               normal    QQ空间                   com.qzone\n",
       "1               normal   搜狗输入法  com.sohu.inputmethod.sogou\n",
       "2               normal   UC浏览器                com.UCMobile\n",
       "3               normal  QQ同步助手           com.tencent.qqpim\n",
       "4               normal      京东       com.jingdong.app.mall\n",
       "...                ...     ...                         ...\n",
       "3009  fraud_investment    强国复兴                    uni.khwm\n",
       "3010  fraud_investment      慈联         com.dwrcsaht.hzcelz\n",
       "3011  fraud_investment    强国复兴                    uni.xhno\n",
       "3012  fraud_investment    共富工程                    uni.bckx\n",
       "3013        fraud_loan    微粒分期  chdhcdbc.ecdddgad.bbegehce\n",
       "\n",
       "[3014 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "normal_apps_path = Path(\"/run/media/mix/64B2AAFCB2AAD1BA/ExAPP/apps.csv\")\n",
    "normal_apps = pd.read_csv(normal_apps_path)\n",
    "\n",
    "malware_paths = [*Path(\"/run/media/mix/64B2AAFCB2AAD1BA/APP/\").glob(\"**/*.xlsx\")]\n",
    "malware_apps = pd.concat(pd.read_excel(file) for file in malware_paths)\n",
    "\n",
    "merged = pd.DataFrame(columns=[\"type\", \"name\", \"pkg_name\"])\n",
    "\n",
    "for name, pkg_name, *_ in normal_apps.values:\n",
    "    merged.loc[len(merged)] = [\"normal\", name, pkg_name]\n",
    "\n",
    "for type, name, pkg_name, *_ in malware_apps.values:\n",
    "    merged.loc[len(merged)] = [\n",
    "        {\"投资理财\": \"fraud_investment\", \"贷款诈骗\": \"fraud_loan\"}[type],\n",
    "        name,\n",
    "        pkg_name,\n",
    "    ]\n",
    "\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "conn = sqlite3.connect(\"./malware.db\")\n",
    "\n",
    "# [pkg_name, [{'path': '/', 'sha256': '...'}, ...]]\n",
    "unique_files_per_app = pd.DataFrame(\n",
    "    columns=[\"pkg_name\", \"unique_files\"],\n",
    "    data=conn.execute(\n",
    "        \"SELECT pkg_name, unique_files FROM unique_files_per_app\"\n",
    "    ).fetchall(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e14c56b3a404169a10448e1f764dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3014 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "      <th>pkg_name</th>\n",
       "      <th>permissions</th>\n",
       "      <th>activities</th>\n",
       "      <th>services</th>\n",
       "      <th>receivers</th>\n",
       "      <th>providers</th>\n",
       "      <th>unique_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ空间</td>\n",
       "      <td>com.qzone</td>\n",
       "      <td>[oicq.wlogin_sdk.permission.WloginProvider.REA...</td>\n",
       "      <td>[com.tencent.sc.activity.SplashActivity, com.q...</td>\n",
       "      <td>[com.qq.e.comm.DownloadService, com.tencent.up...</td>\n",
       "      <td>[com.qzonex.module.upgrade.service.YYBService$...</td>\n",
       "      <td>[com.tencent.component.app.ServiceManager.Prov...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>搜狗输入法</td>\n",
       "      <td>com.sohu.inputmethod.sogou</td>\n",
       "      <td>[android.permission.QUERY_ALL_PACKAGES, androi...</td>\n",
       "      <td>[com.sogou.stick.route.HostFileReceiverActivit...</td>\n",
       "      <td>[com.sohu.inputmethod.sogou.SogouIME, com.sogo...</td>\n",
       "      <td>[com.sogou.imskit.feature.settings.status.Boot...</td>\n",
       "      <td>[com.sogou.bu.ipc.provider.SKeyboardProvider, ...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/MANI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>UC浏览器</td>\n",
       "      <td>com.UCMobile</td>\n",
       "      <td>[android.permission.ACCESS_COARSE_LOCATION, an...</td>\n",
       "      <td>[com.uc.browser.FavoriteActivity, com.uc.brows...</td>\n",
       "      <td>[com.uc.deployment.UpgradePatchResultService, ...</td>\n",
       "      <td>[com.alipay.mobile.command.trigger.NotifyTrigg...</td>\n",
       "      <td>[com.UCMobile.main.FileProvider, com.uc.base.p...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>QQ同步助手</td>\n",
       "      <td>com.tencent.qqpim</td>\n",
       "      <td>[com.android.permission.GET_INSTALLED_APPS, an...</td>\n",
       "      <td>[com.tencent.qqpim.ui.autocheck.page.PerReqAct...</td>\n",
       "      <td>[com.tencent.ep.pushleague.impl.PushLeagueServ...</td>\n",
       "      <td>[com.tencent.qqpim.apps.health.news.HealthNews...</td>\n",
       "      <td>[com.tencent.qqpim.common.goldsdk.db.GoldDBPro...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>京东</td>\n",
       "      <td>com.jingdong.app.mall</td>\n",
       "      <td>[android.permission.REORDER_TASKS, android.per...</td>\n",
       "      <td>[com.jd.lib.developermode.home.DevModeMainActi...</td>\n",
       "      <td>[com.jingdong.app.mall.update.PausableDownload...</td>\n",
       "      <td>[com.jingdong.app.mall.widget.JdWidget, com.ji...</td>\n",
       "      <td>[androidx.core.content.FileProvider, com.jingd...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.khwm</td>\n",
       "      <td>[android.permission.INTERNET, android.permissi...</td>\n",
       "      <td>[io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...</td>\n",
       "      <td>[io.dcloud.sdk.base.service.DownloadService]</td>\n",
       "      <td>[com.taobao.weex.WXGlobalEventReceiver]</td>\n",
       "      <td>[io.dcloud.common.util.DCloud_FileProvider, io...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>慈联</td>\n",
       "      <td>com.dwrcsaht.hzcelz</td>\n",
       "      <td>[android.permission.INTERNET, android.permissi...</td>\n",
       "      <td>[com.pub.zgcishan.MainActivity, com.pub.zgcish...</td>\n",
       "      <td>[androidx.work.impl.background.systemalarm.Sys...</td>\n",
       "      <td>[com.pichillilorenzo.flutter_inappwebview.chro...</td>\n",
       "      <td>[vn.hunghd.flutterdownloader.DownloadedFilePro...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>强国复兴</td>\n",
       "      <td>uni.xhno</td>\n",
       "      <td>[android.permission.INTERNET, android.permissi...</td>\n",
       "      <td>[io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...</td>\n",
       "      <td>[io.dcloud.sdk.base.service.DownloadService]</td>\n",
       "      <td>[com.taobao.weex.WXGlobalEventReceiver]</td>\n",
       "      <td>[io.dcloud.common.util.DCloud_FileProvider, io...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>fraud_investment</td>\n",
       "      <td>共富工程</td>\n",
       "      <td>uni.bckx</td>\n",
       "      <td>[android.permission.INTERNET, android.permissi...</td>\n",
       "      <td>[io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...</td>\n",
       "      <td>[io.dcloud.sdk.base.service.DownloadService]</td>\n",
       "      <td>[com.taobao.weex.WXGlobalEventReceiver]</td>\n",
       "      <td>[io.dcloud.common.util.DCloud_FileProvider, io...</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>fraud_loan</td>\n",
       "      <td>微粒分期</td>\n",
       "      <td>chdhcdbc.ecdddgad.bbegehce</td>\n",
       "      <td>[android.permission.INTERNET, android.permissi...</td>\n",
       "      <td>[com.weilifenqi.ui.activitys.MT5ACT, com.weili...</td>\n",
       "      <td>[com.weilifenqi.gzd.FZGB0Service, com.dtf.wish...</td>\n",
       "      <td>[com.base.commonlibrary.netstate.NetworkStateR...</td>\n",
       "      <td>[androidx.core.content.FileProvider, com.just....</td>\n",
       "      <td>[resources/AndroidManifest.xml, resources/META...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2993 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type   label                    pkg_name  \\\n",
       "0               normal    QQ空间                   com.qzone   \n",
       "1               normal   搜狗输入法  com.sohu.inputmethod.sogou   \n",
       "2               normal   UC浏览器                com.UCMobile   \n",
       "3               normal  QQ同步助手           com.tencent.qqpim   \n",
       "4               normal      京东       com.jingdong.app.mall   \n",
       "...                ...     ...                         ...   \n",
       "2988  fraud_investment    强国复兴                    uni.khwm   \n",
       "2989  fraud_investment      慈联         com.dwrcsaht.hzcelz   \n",
       "2990  fraud_investment    强国复兴                    uni.xhno   \n",
       "2991  fraud_investment    共富工程                    uni.bckx   \n",
       "2992        fraud_loan    微粒分期  chdhcdbc.ecdddgad.bbegehce   \n",
       "\n",
       "                                            permissions  \\\n",
       "0     [oicq.wlogin_sdk.permission.WloginProvider.REA...   \n",
       "1     [android.permission.QUERY_ALL_PACKAGES, androi...   \n",
       "2     [android.permission.ACCESS_COARSE_LOCATION, an...   \n",
       "3     [com.android.permission.GET_INSTALLED_APPS, an...   \n",
       "4     [android.permission.REORDER_TASKS, android.per...   \n",
       "...                                                 ...   \n",
       "2988  [android.permission.INTERNET, android.permissi...   \n",
       "2989  [android.permission.INTERNET, android.permissi...   \n",
       "2990  [android.permission.INTERNET, android.permissi...   \n",
       "2991  [android.permission.INTERNET, android.permissi...   \n",
       "2992  [android.permission.INTERNET, android.permissi...   \n",
       "\n",
       "                                             activities  \\\n",
       "0     [com.tencent.sc.activity.SplashActivity, com.q...   \n",
       "1     [com.sogou.stick.route.HostFileReceiverActivit...   \n",
       "2     [com.uc.browser.FavoriteActivity, com.uc.brows...   \n",
       "3     [com.tencent.qqpim.ui.autocheck.page.PerReqAct...   \n",
       "4     [com.jd.lib.developermode.home.DevModeMainActi...   \n",
       "...                                                 ...   \n",
       "2988  [io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...   \n",
       "2989  [com.pub.zgcishan.MainActivity, com.pub.zgcish...   \n",
       "2990  [io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...   \n",
       "2991  [io.dcloud.PandoraEntry, io.dcloud.PandoraEntr...   \n",
       "2992  [com.weilifenqi.ui.activitys.MT5ACT, com.weili...   \n",
       "\n",
       "                                               services  \\\n",
       "0     [com.qq.e.comm.DownloadService, com.tencent.up...   \n",
       "1     [com.sohu.inputmethod.sogou.SogouIME, com.sogo...   \n",
       "2     [com.uc.deployment.UpgradePatchResultService, ...   \n",
       "3     [com.tencent.ep.pushleague.impl.PushLeagueServ...   \n",
       "4     [com.jingdong.app.mall.update.PausableDownload...   \n",
       "...                                                 ...   \n",
       "2988       [io.dcloud.sdk.base.service.DownloadService]   \n",
       "2989  [androidx.work.impl.background.systemalarm.Sys...   \n",
       "2990       [io.dcloud.sdk.base.service.DownloadService]   \n",
       "2991       [io.dcloud.sdk.base.service.DownloadService]   \n",
       "2992  [com.weilifenqi.gzd.FZGB0Service, com.dtf.wish...   \n",
       "\n",
       "                                              receivers  \\\n",
       "0     [com.qzonex.module.upgrade.service.YYBService$...   \n",
       "1     [com.sogou.imskit.feature.settings.status.Boot...   \n",
       "2     [com.alipay.mobile.command.trigger.NotifyTrigg...   \n",
       "3     [com.tencent.qqpim.apps.health.news.HealthNews...   \n",
       "4     [com.jingdong.app.mall.widget.JdWidget, com.ji...   \n",
       "...                                                 ...   \n",
       "2988            [com.taobao.weex.WXGlobalEventReceiver]   \n",
       "2989  [com.pichillilorenzo.flutter_inappwebview.chro...   \n",
       "2990            [com.taobao.weex.WXGlobalEventReceiver]   \n",
       "2991            [com.taobao.weex.WXGlobalEventReceiver]   \n",
       "2992  [com.base.commonlibrary.netstate.NetworkStateR...   \n",
       "\n",
       "                                              providers  \\\n",
       "0     [com.tencent.component.app.ServiceManager.Prov...   \n",
       "1     [com.sogou.bu.ipc.provider.SKeyboardProvider, ...   \n",
       "2     [com.UCMobile.main.FileProvider, com.uc.base.p...   \n",
       "3     [com.tencent.qqpim.common.goldsdk.db.GoldDBPro...   \n",
       "4     [androidx.core.content.FileProvider, com.jingd...   \n",
       "...                                                 ...   \n",
       "2988  [io.dcloud.common.util.DCloud_FileProvider, io...   \n",
       "2989  [vn.hunghd.flutterdownloader.DownloadedFilePro...   \n",
       "2990  [io.dcloud.common.util.DCloud_FileProvider, io...   \n",
       "2991  [io.dcloud.common.util.DCloud_FileProvider, io...   \n",
       "2992  [androidx.core.content.FileProvider, com.just....   \n",
       "\n",
       "                                           unique_files  \n",
       "0     [resources/AndroidManifest.xml, resources/META...  \n",
       "1     [resources/AndroidManifest.xml, resources/MANI...  \n",
       "2     [resources/AndroidManifest.xml, resources/META...  \n",
       "3     [resources/AndroidManifest.xml, resources/META...  \n",
       "4     [resources/AndroidManifest.xml, resources/META...  \n",
       "...                                                 ...  \n",
       "2988  [resources/AndroidManifest.xml, resources/META...  \n",
       "2989  [resources/AndroidManifest.xml, resources/META...  \n",
       "2990  [resources/AndroidManifest.xml, resources/META...  \n",
       "2991  [resources/AndroidManifest.xml, resources/META...  \n",
       "2992  [resources/AndroidManifest.xml, resources/META...  \n",
       "\n",
       "[2993 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_merged = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"type\",\n",
    "        \"label\",\n",
    "        \"pkg_name\",\n",
    "        \"permissions\",\n",
    "        \"activities\",\n",
    "        \"services\",\n",
    "        \"receivers\",\n",
    "        \"providers\",\n",
    "        \"unique_files\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for type, label, pkg_name, *_ in tqdm(merged.values):\n",
    "    result = conn.execute(\n",
    "        \"SELECT permissions, activities, services, receivers, providers FROM apps WHERE pkg_name = ?\",\n",
    "        (pkg_name,),\n",
    "    ).fetchone()\n",
    "    if result is None:\n",
    "        continue\n",
    "    permissions, activities, services, receivers, providers = result\n",
    "    # find the unique files\n",
    "    unique_files, *_ = unique_files_per_app[\n",
    "        unique_files_per_app[\"pkg_name\"] == pkg_name\n",
    "    ][\"unique_files\"].values\n",
    "    unique_file_paths = [file[\"path\"] for file in json.loads(unique_files)]\n",
    "    metadata_merged.loc[len(metadata_merged)] = [\n",
    "        type,\n",
    "        label,\n",
    "        pkg_name,\n",
    "        json.loads(permissions),\n",
    "        json.loads(activities),\n",
    "        json.loads(services),\n",
    "        json.loads(receivers),\n",
    "        json.loads(providers),\n",
    "        unique_file_paths,\n",
    "    ]\n",
    "\n",
    "metadata_merged.to_csv(\"metadata_merged.csv\", index=False)\n",
    "\n",
    "metadata_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(114514)\n",
    "\n",
    "unique_types = metadata_merged[\"type\"].unique()\n",
    "num_labels = len(unique_types)\n",
    "\n",
    "# Create a label mapping\n",
    "label_dict = {label: i for i, label in enumerate(unique_types)}\n",
    "id2label = {i: label for label, i in label_dict.items()}\n",
    "\n",
    "text_label = pd.DataFrame(columns=[\"text\", \"label\"])\n",
    "for (\n",
    "    type_,\n",
    "    label,\n",
    "    pkg_name,\n",
    "    permissions,\n",
    "    activities,\n",
    "    services,\n",
    "    receivers,\n",
    "    providers,\n",
    "    unique_files,\n",
    ") in metadata_merged.values:\n",
    "    texts = [\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"pkg_name\": pkg_name,\n",
    "            },\n",
    "            ensure_ascii=False,\n",
    "            separators=(\",\", \":\"),\n",
    "        ),\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"pkg_name\": pkg_name,\n",
    "                \"manifest\": {\n",
    "                    \"permissions\": permissions,\n",
    "                    \"activities\": activities,\n",
    "                    \"services\": services,\n",
    "                    \"receivers\": receivers,\n",
    "                    \"providers\": providers,\n",
    "                },\n",
    "            },\n",
    "            ensure_ascii=False,\n",
    "            separators=(\",\", \":\"),\n",
    "        ),\n",
    "        json.dumps(\n",
    "            {\n",
    "                \"label\": label,\n",
    "                \"pkg_name\": pkg_name,\n",
    "                \"unique_files\": unique_files,\n",
    "            },\n",
    "            ensure_ascii=False,\n",
    "            separators=(\",\", \":\"),\n",
    "        ),\n",
    "    ]\n",
    "    for text in texts:\n",
    "        text_label.loc[len(text_label)] = [\n",
    "            text,\n",
    "            label_dict[type_],\n",
    "        ]\n",
    "\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    text_label[\"text\"].values,\n",
    "    text_label[\"label\"].values,\n",
    "    test_size=0.1,\n",
    "    random_state=114514,\n",
    "    stratify=text_label[\"label\"].values,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerFast,\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "# Create a custom dataset\n",
    "class AppDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, texts, labels, tokenizer: PreTrainedTokenizerFast, max_length: int = 512\n",
    "    ):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 17943\n",
      "Validation dataset size: 898\n"
     ]
    }
   ],
   "source": [
    "# ... existing code ...\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# First, we need to convert text to features for SMOTE\n",
    "# SMOTE can't work directly on text, so we'll use TF-IDF to vectorize\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(random_state=114514)\n",
    "X_train_resampled, y_train_resampled, *_ = smote.fit_resample(X_train_vec, train_labels)\n",
    "\n",
    "# Convert resampled indices back to text\n",
    "# We need to handle the synthetic samples\n",
    "train_texts_resampled = []\n",
    "for i, x_vec in enumerate(X_train_resampled):\n",
    "    if i < len(train_texts):  # Original sample\n",
    "        train_texts_resampled.append(train_texts[i])\n",
    "    else:  # Synthetic sample\n",
    "        # Find nearest neighbors to create a realistic text representation\n",
    "        # Here we use the original text of the same class\n",
    "        same_class_indices = [\n",
    "            j for j, y in enumerate(train_labels) if y == y_train_resampled[i]\n",
    "        ]\n",
    "        if same_class_indices:\n",
    "            # Choose a random original text from the same class\n",
    "            idx = same_class_indices[\n",
    "                torch.randint(0, len(same_class_indices), (1,)).item()\n",
    "            ]\n",
    "            train_texts_resampled.append(train_texts[idx])\n",
    "\n",
    "# Create datasets with resampled data\n",
    "train_dataset: AppDataset = AppDataset(\n",
    "    train_texts_resampled, y_train_resampled, tokenizer\n",
    ")\n",
    "val_dataset: AppDataset = AppDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "# ... existing code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleanup memories\n",
    "import gc\n",
    "\n",
    "for df in (metadata_merged, merged, normal_apps, malware_apps, unique_files_per_app):\n",
    "    df.drop(df.index, inplace=True)\n",
    "    del df\n",
    "\n",
    "\n",
    "conn.close()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mix/Documents/MalClass/.venv/lib/python3.13/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    \"roberta-base\", num_labels=num_labels, id2label=id2label, label2id=label_dict\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from transformers import PreTrainedModel\n",
    "from transformers.optimization import Optimizer\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_epoch(\n",
    "    model: PreTrainedModel,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    scheduler: LRScheduler,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model: PreTrainedModel, dataloader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(dataloader), all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca2f0bd0af14e2f9f0b14f5f18e9481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257eedfbf2f74551b884b314e7685682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0288\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "          normal       1.00      0.99      0.99       664\n",
      "fraud_investment       0.98      0.99      0.98       201\n",
      "      fraud_loan       0.89      0.97      0.93        33\n",
      "\n",
      "        accuracy                           0.99       898\n",
      "       macro avg       0.96      0.98      0.97       898\n",
      "    weighted avg       0.99      0.99      0.99       898\n",
      "\n",
      "Saved best model!\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4a6ae54a4d43dabc10757133d84812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/4486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    val_loss, val_preds, val_labels = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(val_labels, val_preds, target_names=unique_types))\n",
    "\n",
    "    # Save the best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_roberta_model_ultimate.pt\")\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_roberta_model_ultimate.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
